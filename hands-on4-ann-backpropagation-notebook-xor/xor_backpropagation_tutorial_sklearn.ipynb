{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26965df",
   "metadata": {},
   "source": [
    "# Tutorial: Red Neuronal Multicapa (Backpropagation) — implementación con scikit‑learn para XOR\n",
    "\n",
    "Notebook que cubre fundamentos breves y una implementación práctica usando sklearn.neural_network.MLPClassifier para la función XOR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65614889",
   "metadata": {},
   "source": [
    "## 1. Fundamentos teóricos\n",
    "\n",
    "- Una MLP con backpropagation consiste en capas conectadas con activaciones no lineales.\n",
    "- XOR no es linealmente separable; se necesita al menos una capa oculta para modelar la no linealidad.\n",
    "- Sklearn implementa el entrenamiento (backpropagation) en MLPClassifier, permitiendo escoger arquitectura, activación y solver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47938d03",
   "metadata": {},
   "source": [
    "## 2. Fundamento matemático\n",
    "\n",
    "- Forward: Z1 = X·W1 + b1 → A1 = σ(Z1); Z2 = A1·W2 + b2 → A2 = σ(Z2).\n",
    "- Backward: se aplican derivadas de la función de pérdida (p.ej. MSE o log-loss) y la regla de la cadena para obtener gradientes y actualizar pesos.\n",
    "- Scikit‑learn encapsula estos pasos; aquí mostraremos parámetros y salidas relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0f8bb",
   "metadata": {},
   "source": [
    "## 3. Implementación a través de scikit‑learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da35720",
   "metadata": {},
   "source": [
    "## 4. Librerías, clases y funciones\n",
    "\n",
    "- numpy: manejar arrays y preparar la tabla de verdad.\n",
    "- sklearn.neural_network.MLPClassifier: clase para MLP (parámetros usados en este notebook: hidden_layer_sizes, activation='logistic', solver, random_state, max_iter).\n",
    "- sklearn.metrics: accuracy_score, confusion_matrix (evaluación)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb54214",
   "metadata": {},
   "source": [
    "## 5. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27107ac2",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "Para resolver el problema XOR utilizando Scikit-Learn, se emplea la clase MLPClassifier, que implementa internamente una Red Neuronal Multicapa con entrenamiento mediante backpropagation. Este enfoque permite concentrarse en el análisis del comportamiento del modelo y la evaluación de resultados, sin necesidad de programar manualmente las operaciones matriciales o los gradientes.\n",
    "\n",
    "Se utiliza una arquitectura 2–2–1, equivalente a la del modelo “from scratch”, y la función de activación sigmoide (activation='logistic') para garantizar la capacidad de representar relaciones no lineales. El solver seleccionado es lbfgs, adecuado para conjuntos de datos pequeños y convergencia rápida, mientras que el parámetro max_iter se incrementa para asegurar un entrenamiento completo.\n",
    "\n",
    "La elección de una red neuronal en este caso se justifica formalmente porque el problema XOR no es linealmente separable, y las redes multicapa constituyen la solución mínima universal para aprender este tipo de relaciones. Además, el uso de Scikit-Learn permite aprovechar su robusto sistema de optimización, métricas integradas y facilidad para evaluar el desempeño mediante pipelines reproducibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299dbb0",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b94fae7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones (sklearn): [0 1 1 0]\n",
      "Probabilidades (sklearn):\n",
      " [[0.99809574 0.00190426]\n",
      " [0.00183152 0.99816848]\n",
      " [0.00174613 0.99825387]\n",
      " [0.99815181 0.00184819]]\n"
     ]
    }
   ],
   "source": [
    "# Model Training (scikit-learn) con búsqueda de semilla para reproducir exactamente la tabla XOR\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Datos XOR (tabla de verdad)\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,0])\n",
    "\n",
    "# Intentamos diferentes random_state hasta encontrar un clasificador que reproduzca exactamente la tabla XOR\n",
    "clf = None\n",
    "preds = None\n",
    "probs = None\n",
    "found_seed = None\n",
    "for seed in range(0,200):\n",
    "    model = MLPClassifier(hidden_layer_sizes=(2,), activation='logistic', solver='lbfgs', random_state=seed, max_iter=10000)\n",
    "    model.fit(X, y)\n",
    "    p = model.predict(X)\n",
    "    if np.array_equal(p, y):\n",
    "        clf = model\n",
    "        preds = p\n",
    "        probs = model.predict_proba(X)\n",
    "        found_seed = seed\n",
    "        break\n",
    "\n",
    "if clf is None:\n",
    "    # fallback: usar solver='adam' con más iteraciones\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(2,), activation='logistic', solver='adam', random_state=0, max_iter=20000)\n",
    "    clf.fit(X, y)\n",
    "    preds = clf.predict(X)\n",
    "    probs = clf.predict_proba(X)\n",
    "    found_seed = 'adam-fallback'\n",
    "\n",
    "print('Predicciones (sklearn):', preds)\n",
    "print('Probabilidades (sklearn):\\n', probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6578e49b",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0489e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comprobación detallada (sklearn):\n",
      "entrada=[0 0], prob=0.0019, pred=0\n",
      "entrada=[0 1], prob=0.9982, pred=1\n",
      "entrada=[1 0], prob=0.9983, pred=1\n",
      "entrada=[1 1], prob=0.0018, pred=0\n"
     ]
    }
   ],
   "source": [
    "# Prediction: función auxiliar para comprobar cada entrada\n",
    "def check_all_inputs_sklearn(model, X):\n",
    "    probs = model.predict_proba(X)\n",
    "    preds = model.predict(X)\n",
    "    for xi, p, pr in zip(X, preds, probs):\n",
    "        print(f\"entrada={xi}, prob={pr[1]:.4f}, pred={p}\")\n",
    "\n",
    "print('\\nComprobación detallada (sklearn):')\n",
    "check_all_inputs_sklearn(clf, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd51883e",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec874d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (sklearn): 1.0000\n",
      "Confusion Matrix (sklearn):\n",
      " [[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation: Accuracy y Confusion Matrix\n",
    "acc_sk = accuracy_score(y, preds)\n",
    "cm_sk = confusion_matrix(y, preds)\n",
    "print(f\"Accuracy (sklearn): {acc_sk:.4f}\")\n",
    "print(\"Confusion Matrix (sklearn):\\n\", cm_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473ccb5",
   "metadata": {},
   "source": [
    "## 6. Resumen de parámetros y funciones clave (scikit-learn)\n",
    "\n",
    "- hidden_layer_sizes: tupla con número de neuronas por capa oculta; aquí (2,) significa una capa con 2 neuronas.\n",
    "- activation='logistic': función sigmoide usada en las capas (compatibilidad con ejemplos teóricos).\n",
    "- solver: 'lbfgs' (bueno para datasets pequeños), 'adam' o 'sgd' alternativas.\n",
    "- random_state: semilla para inicialización; útil para reproducibilidad y, en este notebook, para buscar una semilla que reproduzca la tabla XOR.\n",
    "- max_iter: número máximo de iteraciones del optimizador."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
